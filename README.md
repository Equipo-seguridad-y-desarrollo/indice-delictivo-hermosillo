# ğŸš¨ Ãndice Delictivo Hermosillo

<a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
    <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
</a>

AnÃ¡lisis geoespacial de reportes a servicios de emergencia en Hermosillo, Sonora, por colonia.

---

## ğŸ“‹ DescripciÃ³n

Este proyecto analiza datos de incidentes policiales y caracterÃ­sticas demogrÃ¡ficas de las colonias de Hermosillo, Sonora, con el objetivo de generar un Ã­ndice delictivo georreferenciado que permita:

- Identificar zonas de mayor incidencia delictiva
- Correlacionar factores demogrÃ¡ficos con Ã­ndices de criminalidad
- Proveer datos geoespaciales para anÃ¡lisis y visualizaciÃ³n

---

## ğŸš€ Estado Actual

### âœ… Completado

- **Descarga de datos**: Migrado de Google Drive a Hugging Face para descarga directa
- **Procesamiento multi-aÃ±o**: Pipeline consolidado para procesar datos 2018-2025 (2.3M registros)
- **EstandarizaciÃ³n de incidentes**: 475 tipos de incidentes mapeados a 198 categorÃ­as Ãºnicas
- **Feature engineering**: 7 columnas derivadas (temporal, categÃ³rica, severidad)
- **Limpieza de colonias**: 2,047 colonias Ãºnicas identificadas (220 grupos con variantes)
- **GeocodificaciÃ³n incremental**: Coordenadas obtenidas vÃ­a Google Maps API con sistema anti-duplicados
- **Limpieza de datos demogrÃ¡ficos**: 659 colonias con informaciÃ³n poblacional
- **DocumentaciÃ³n completa** del proceso de limpieza y normalizaciÃ³n
- ValidaciÃ³n cruzada entre datasets
- AnÃ¡lisis geoespacial de incidentes
- VisualizaciÃ³n de datos en mapas interactivos

### ğŸ”„ En Proceso


---

## ğŸ“Š Datasets

### Datos Crudos (`data/raw/`)

| Archivo | Registros | DescripciÃ³n | Estatus |
|---------|-----------|-------------|-------------|
| `213.xlsx` | 2,297,081 | Incidentes reportados a servicios de emergencia 911 (2018-2025) | Por confirmar |
| `demografia_hermosillo.csv` | 660 | Datos demogrÃ¡ficos por colonia (INEGI 2020) | Confirmado |
| `delitos.csv` | - | CatÃ¡logo de tipos de delitos | Por confirmar |
| `poligonos_hermosillo.csv` | - | PolÃ­gonos geogrÃ¡ficos de colonias | Confirmado |
| `INE_Limpio.shx` | - | PolÃ­gonos geogrÃ¡ficos de colonias, formato shapefile | Confirmado |
| `INE_Limpio.shp` | - | PolÃ­gonos geogrÃ¡ficos de colonias, formato shapefile | Confirmado |
| `INE_Limpio.prj` | - | PolÃ­gonos geogrÃ¡ficos de colonias, formato shapefile | Confirmado |
| `INE_Limpio.dbf` | - | PolÃ­gonos geogrÃ¡ficos de colonias, formato shapefile | Confirmado |

### Datos Intermedios (`data/interim/`)

| Archivo | DescripciÃ³n | Estatus |
|---------|-------------|-------------|
| `reportes_de_incidentes_procesados_2018_2025.csv` | Datos consolidados 2018-2025 con estandarizaciÃ³n y feature engineering (~310MB, 2.3M registros) | Por confirmar |
| `colonias_sin_poblacion.csv` |  | Confirmado |
| `colonias_con_incidentes_sin_poligono.csv` |  | Confirmado |




### Datos Procesados (`data/processed/`)

| Archivo | DescripciÃ³n |
|---------|-------------|
| `colonias_unicas_reportes_911.csv` | 2,047 colonias limpias del dataset policial |
| `colonias_reportes_911_con_coordenadas.csv` | Colonias con coordenadas geogrÃ¡ficas (lat/lng) |
| `colonias_reportes_911_agrupadas_reporte.csv` | Reporte de 220 grupos con variantes ortogrÃ¡ficas detectadas |
| `mapeo_colonias_reportes_911.csv` | Mapeo de colonias originales a normalizadas |
| `demografia_limpio.csv` | Datos demogrÃ¡ficos normalizados |
| `colonias_unicas_demografia.csv` | Lista de colonias Ãºnicas de demografÃ­a |
| `colonias_demografia_con_coordenadas.csv` | - |

---

## ğŸ› ï¸ Scripts Principales

### Pipeline Principal

```bash
# Pipeline completo: descarga y procesamiento de datos
python indice_delictivo_hermosillo_main.py
```

Este script orquesta:
1. **Descarga de datos** desde Hugging Face (`download_raw_data.py`)
2. **Procesamiento interim** con estandarizaciÃ³n y feature engineering (`make_interim_data.py`)

### Procesamiento de Colonias

```bash
# 1. Extraer y normalizar colonias del dataset procesado
python notebooks/extraer_colonias_unicas_reportes_911.py

# 2. GeocodificaciÃ³n incremental (solo colonias nuevas)
python notebooks/geocodificar_colonias_reportes_911.py
```

### Limpieza de DemografÃ­a

```bash
# Normalizar espacios en datos demogrÃ¡ficos
python notebooks/normalizar_espacios_demografia.py
```

### AnÃ¡lisis

```bash
# Analizar calidad de datos demogrÃ¡ficos
python notebooks/analizar_calidad_datos_demografia.py
```

---

## âš™ï¸ ConfiguraciÃ³n

### Requisitos

```bash
# Python 3.10+
pip install -r requirements.txt
```

**Dependencias principales**:
- `pandas>=2.0.0` - ManipulaciÃ³n de datos
- `googlemaps>=4.10.0` - GeocodificaciÃ³n
- `python-dotenv>=1.0.0` - Variables de entorno

### Google Maps API

Para usar el script de geocodificaciÃ³n:

1. ObtÃ©n una API key de [Google Cloud Console](https://console.cloud.google.com/)
2. Habilita la **Geocoding API**
3. Crea un archivo `.env` en la raÃ­z del proyecto:

```env
GOOGLE_MAPS_API_KEY=tu_api_key_aqui
```

âš ï¸ **IMPORTANTE**: Nunca subas tu API key al repositorio. El archivo `.env` estÃ¡ protegido por `.gitignore`.

Ver [`SECURITY.md`](SECURITY.md) para mÃ¡s detalles de seguridad.

---

## ğŸ“– DocumentaciÃ³n

- **[Proceso de Limpieza de Datos](docs/PROCESO_LIMPIEZA_DATOS.md)**: DocumentaciÃ³n completa del flujo de trabajo
- **[Seguridad](SECURITY.md)**: GuÃ­a de manejo seguro de credenciales

---

## ğŸ“ OrganizaciÃ³n del Proyecto

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Datos originales (sin modificar)
â”‚   â””â”€â”€ processed/              # Datos limpios y procesados
â”‚
â”œâ”€â”€ notebooks/                  # Scripts de anÃ¡lisis y procesamiento
â”‚   â”œâ”€â”€ 01_auto_eda_SweetViz.ipynb            # AnÃ¡lisis exploratorio automÃ¡tico usando SweetViz
â”‚   â”œâ”€â”€ 01_auto_eda_ydata.ipynb               # AnÃ¡lisis exploratorio automÃ¡tico usando YDataProfiler
â”‚   â”œâ”€â”€ 02_analisis_exploratorio.ipynb        # AnÃ¡lisis exploratorio manual
â”‚   â”œâ”€â”€ 03_analisis_pca_y_generacion_indices.ipynb    # AnÃ¡lisis PCA
â”‚   â”œâ”€â”€ extraer_colonias_unicas_reportes_911.py
â”‚   â”œâ”€â”€ geocodificar_colonias_reportes_911.py
â”‚   â”œâ”€â”€ normalizar_espacios_demografia.py
â”‚   â”œâ”€â”€ mapa_interactivo_folium_avanzado.py    # Generador de mapa interactivo - mapa_interactivo_hermosillo.html
â”‚   â””â”€â”€ analizar_calidad_datos_demografia.py
â”‚
â”œâ”€â”€ references/                       # DocumentaciÃ³n del proyecto
â”‚   â”œâ”€â”€ Diccionario de Datos para Mapeo de Incidentes.md    # Diccionario de datos
â”‚   â””â”€â”€  AnÃ¡lisis y JustificaciÃ³n del Sistema de ClasificaciÃ³n de Severidad de Incidentes para Servicios de Emergencia.md
|
â”œâ”€â”€ docs/                       # DocumentaciÃ³n del proyecto
â”‚   â”œâ”€â”€ CAMBIO_FUENTE_POLIGONOS.md    # Diccionario de datos
â”‚   â”œâ”€â”€ DICCIONARIO_DE_DATOS.md
â”‚   â”œâ”€â”€ GIT_DATA_MANAGEMENT.md
â”‚   â”œâ”€â”€ METODOLOGIA_PCA.md
â”‚   â”œâ”€â”€ PROCESO_LIMPIEZA_DATOS.md
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ RESUMEN_EJECUTIVO.md
|
â”œâ”€â”€ reports/                       # Reportes de anÃ¡lisis
â”‚   â”œâ”€â”€ figures/                      # GrÃ¡ficas en PNG del anÃ¡lisis exploratorio manual
â”‚   â”œâ”€â”€1.0-EDA_YDataProfiler.html     # Primer reporte automatizado EDA
â”‚   â”œâ”€â”€ 2.0-EDA_YDataProfiler.html    # Segundo reporte automatizado EDA
â”‚   â”œâ”€â”€ Presentacion_delitoHMO.pptx   # PresentaciÃ³n de hallazgos de anÃ¡lisis exploratorio, PowerPoint
â”‚   â””â”€â”€ reporte_delitosHMO.html       # Reporte de hallazgos y anÃ¡lisis exploratorio
â”‚
â”œâ”€â”€ .env                        # Variables de entorno (NO SUBIR)
â”œâ”€â”€ .gitignore                  # Archivos ignorados por Git
â”œâ”€â”€ SECURITY.md                 # GuÃ­a de seguridad
â”œâ”€â”€ requirements.txt            # Requisitos para environment (librerÃ­as, interpretes, etc.)
â”œâ”€â”€ mapa_interactivo_hermosillo.html    #Mapa interactivo de Hermosillo con informaciÃ³n demogrÃ¡fica y de delitos
â””â”€â”€ README.md                   # Este archivo
```

---

## ğŸ”¬ MetodologÃ­a de Limpieza

### Pipeline de Datos

**Flujo**: Hugging Face â†’ Raw â†’ Interim â†’ Processed

1. **Descarga** (`download_raw_data.py`):
   - Fuente: Hugging Face dataset `Marcelinux/llamadas911_colonias_hermosillo_2018_2025`
   - Formato: Excel multi-hoja (8 hojas: 2018-2025)
   - Output: `data/raw/reportes_de_incidentes_2018_2025.csv`

2. **Procesamiento Interim** (`make_interim_data.py`):
   - **EstandarizaciÃ³n**: 475 tipos de incidentes â†’ 198 Ãºnicos (mapa de normalizaciÃ³n)
   - **CategorizaciÃ³n**: 12 categorÃ­as principales de incidentes
   - **Niveles de severidad**: BAJA, MEDIA, ALTA (200 reglas)
   - **Feature Engineering**:
     * `ParteDelDia`: Madrugada/MaÃ±ana/Tarde/Noche
     * `DiaDeLaSemana`: Lunes-Domingo
     * `EsFinDeSemana`: Boolean
     * `Mes`: 1-12
     * `EsQuincena`: Boolean (dÃ­as 1, 14-16, 28-31)
   - **OptimizaciÃ³n**: Columnas temporales redundantes eliminadas (FECHA, HORA, AÃ±o_Reporte)
   - Output: `data/interim/reportes_de_incidentes_procesados_2018_2025.csv` (~310MB)

### NormalizaciÃ³n de Colonias

**Problema**: 2,296 nombres de colonias con mÃºltiples errores ortogrÃ¡ficos

**SoluciÃ³n**: Algoritmo de fuzzy matching que:
1. Normaliza texto (acentos, mayÃºsculas, espacios)
2. Calcula similitud entre nombres (90% umbral)
3. Valida que sean variantes reales (no colonias diferentes)
4. Selecciona el nombre mÃ¡s frecuente como representativo

**Resultado**: 2,047 colonias Ãºnicas consolidadas (220 grupos con variantes)

### GeocodificaciÃ³n Incremental

**Proceso**: Google Maps Geocoding API con sistema anti-duplicados
- DetecciÃ³n automÃ¡tica de colonias ya geocodificadas
- Solo procesa colonias nuevas (ahorro de costos)
- Formato: `"{colonia}, Hermosillo, Sonora, MÃ©xico"`
- Delay: 0.2s entre peticiones
- Tasa de Ã©xito: ~100%

---

## ï¿½ AnÃ¡lisis Exploratorio de Datos

El anÃ¡lisis exploratorio de datos (EDA) del proyecto se realiza a travÃ©s de mÃºltiples enfoques:

### ğŸ“ AnÃ¡lisis Automatizados
Los anÃ¡lisis automatizados se encuentran en los siguientes notebooks:

- **`notebooks/01_auto_eda_SweetViz.ipynb`**: AnÃ¡lisis automÃ¡tico interactivo usando **SweetViz**, que genera reportes HTML con perfiles de datos, distribuciones, correlaciones y relaciones bivariadas
- **`notebooks/01_auto_eda_ydata.ipynb`**: AnÃ¡lisis automÃ¡tico usando **YData Profiling**, que proporciona un anÃ¡lisis profundo de calidad de datos, variables, interacciones y alertas

### ğŸ”¬ AnÃ¡lisis Exploratorio Manual
- **`notebooks/02_analisis_exploratorio.ipynb`**: AnÃ¡lisis exploratorio completo realizado manualmente que incluye:
  - âœ… AnÃ¡lisis detallado de datos faltantes
  - âœ… DetecciÃ³n de anomalÃ­as mediante mÃºltiples tÃ©cnicas (Z-Score, IQR, Isolation Forest)
  - âœ… VisualizaciÃ³n de relaciones entre variables (pair plots, distribuciones, scatter plots)
  - âœ… AnÃ¡lisis de correlaciÃ³n y multicolinealidad
  - âœ… ReducciÃ³n dimensional mediante PCA
  - âœ… Conclusiones estadÃ­sticas y recomendaciones accionables

---

## ï¿½ğŸ“ˆ MÃ©tricas de Calidad

| Dataset | Registros | Colonias Ãšnicas | Variantes Detectadas | Calidad |
|---------|-----------|-----------------|----------------------|---------|
| Datos Policiales (2018-2025) | 2,297,081 | 2,047 | 220 grupos (-9.8%) | â­â­â­â­ |
| Datos DemogrÃ¡ficos | 660 | 659 | 1 (-0.15%) | â­â­â­â­â­ |

### EstandarizaciÃ³n de Incidentes

| MÃ©trica | Valor |
|---------|-------|
| Tipos originales | 475 |
| Tipos estandarizados | 198 |
| CategorÃ­as principales | 12 |
| Niveles de severidad | 3 (BAJA, MEDIA, ALTA) |
| Periodo de datos | 2018-01-01 a 2025-09-30 |

---

## ğŸ‘¥ Equipo

**OrganizaciÃ³n**: Equipo-seguridad-y-desarrollo  
**Rama actual**: `colonias_geolocalizadas_unificadas`

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo licencia [LICENSE](LICENSE).

---

## ğŸ¤ Contribuciones

Para contribuir al proyecto:
1. Revisa la documentaciÃ³n en [`docs/`](docs/)
2. Sigue las convenciones de nomenclatura establecidas
3. Documenta todos los cambios importantes
4. Nunca subas credenciales o API keys

---

*Ãšltima actualizaciÃ³n: 18 de noviembre de 2025*

## Project Organization

```
â”œâ”€â”€ LICENSE            <- Open-source license if one is chosen
â”œâ”€â”€ Makefile           <- Makefile with convenience commands like `make data` or `make train`
â”œâ”€â”€ README.md          <- The top-level README for developers using this project.
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ external       <- Data from third party sources.
â”‚   â”œâ”€â”€ interim        <- Intermediate data that has been transformed.
â”‚   â”œâ”€â”€ processed      <- The final, canonical data sets for modeling.
â”‚   â””â”€â”€ raw            <- The original, immutable data dump.
â”‚
â”œâ”€â”€ docs               <- A default mkdocs project; see www.mkdocs.org for details
â”‚
â”œâ”€â”€ models             <- Trained and serialized models, model predictions, or model summaries
â”‚
â”œâ”€â”€ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
â”‚                         the creator's initials, and a short `-` delimited description, e.g.
â”‚                         `1.0-jqp-initial-data-exploration`.
â”‚
â”œâ”€â”€ pyproject.toml     <- Project configuration file with package metadata for 
â”‚                         indice-delictivo-hermosillo and configuration for tools like black
â”‚
â”œâ”€â”€ references         <- Data dictionaries, manuals, and all other explanatory materials.
â”‚
â”œâ”€â”€ -reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
â”‚   â””â”€â”€ figures        <- Generated graphics and figures to be used in reporting
â”‚
â”œâ”€â”€ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
â”‚                         generated with `pip freeze > requirements.txt`
â”‚
â”œâ”€â”€ setup.cfg          <- Configuration file for flake8
â”‚
â””â”€â”€ indice-delictivo-hermosillo   <- Source code for use in this project.
    â”‚
    â”œâ”€â”€ __init__.py             <- Makes indice-delictivo-hermosillo a Python module
    â”‚
    â”œâ”€â”€ config.py               <- Store useful variables and configuration
    â”‚
    â”œâ”€â”€ dataset.py              <- Scripts to download or generate data
    â”‚
    â”œâ”€â”€ features.py             <- Code to create features for modeling
    â”‚
    â”œâ”€â”€ modeling                
    â”‚   â”œâ”€â”€ __init__.py 
    â”‚   â”œâ”€â”€ predict.py          <- Code to run model inference with trained models          
    â”‚   â””â”€â”€ train.py            <- Code to train models
    â”‚
    â””â”€â”€ plots.py                <- Code to create visualizations
```

--------

