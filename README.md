# ğŸš¨ Ãndice Delictivo Hermosillo

<a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
    <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
</a>

AnÃ¡lisis geoespacial de reportes a servicios de emergencia en Hermosillo, Sonora, por colonia.

---

## ğŸ“‹ DescripciÃ³n

Este proyecto analiza datos de incidentes policiales y caracterÃ­sticas demogrÃ¡ficas de las colonias de Hermosillo, Sonora, con el objetivo de generar un Ã­ndice delictivo georreferenciado que permita:

- Identificar zonas de mayor incidencia delictiva
- Correlacionar factores demogrÃ¡ficos con Ã­ndices de criminalidad
- Proveer datos geoespaciales para anÃ¡lisis y visualizaciÃ³n

---

## ğŸš€ Estado Actual - v4.0

### âœ… Completado

- **Descarga de datos**: Migrado de Google Drive a Hugging Face para descarga directa
- **Procesamiento multi-aÃ±o**: Pipeline consolidado para procesar datos 2018-2025 (2.3M registros)
- **EstandarizaciÃ³n de incidentes**: 475 tipos de incidentes mapeados a 198 categorÃ­as Ãºnicas
- **Feature engineering**: 10 columnas derivadas (temporal, categÃ³rica, severidad)
- **Limpieza de colonias**: 2,047 colonias Ãºnicas identificadas (220 grupos con variantes)
- **GeocodificaciÃ³n incremental**: Coordenadas obtenidas vÃ­a Google Maps API con sistema anti-duplicados
- **Limpieza de datos demogrÃ¡ficos**: 659 colonias con informaciÃ³n poblacional
- **UnificaciÃ³n completa**: Pipeline de 3 pasos (spatial + buffer + nombre) - 100% demografÃ­a asignada
- **Dashboard interactivo**: Mapa con 5 capas de visualizaciÃ³n, popups y filtros
- **DocumentaciÃ³n completa**: Proceso de limpieza, unificaciÃ³n y mejores prÃ¡cticas Git

### ğŸ“Š Cobertura de Datos (v4.0)

- âœ… **658/658 (100%)** colonias demogrÃ¡ficas asignadas a polÃ­gonos
- âœ… **2,227,287/2,297,081 (97%)** incidentes georreferenciados
- âœ… **444/693 (64.1%)** polÃ­gonos con demografÃ­a completa
- âœ… **435/693 (62.8%)** polÃ­gonos con Ã­ndice de riesgo calculado

---

## ğŸ“Š Datasets

### Datos Crudos (`data/raw/`)

| Archivo | Registros | DescripciÃ³n |
|---------|-----------|-------------|
| `213.xlsx` | 2,297,081 | Incidentes reportados a servicios de emergencia 911 (2018-2025) |
| `demografia_hermosillo.csv` | 660 | Datos demogrÃ¡ficos por colonia (INEGI 2020) |
| `delitos.csv` | - | CatÃ¡logo de tipos de delitos |
| `poligonos_hermosillo.csv` | - | PolÃ­gonos geogrÃ¡ficos de colonias |

### Datos Intermedios (`data/interim/`)

| Archivo | DescripciÃ³n |
|---------|-------------|
| `reportes_de_incidentes_procesados_2018_2025.csv` | Datos consolidados 2018-2025 con estandarizaciÃ³n y feature engineering (~310MB, 2.3M registros) |

### Datos Procesados (`data/processed/`)

| Archivo | DescripciÃ³n |
|---------|-------------|
| `colonias_unicas_reportes_911.csv` | 2,047 colonias limpias del dataset policial |
| `colonias_reportes_911_con_coordenadas.csv` | Colonias con coordenadas geogrÃ¡ficas (lat/lng) |
| `colonias_reportes_911_agrupadas_reporte.csv` | Reporte de 220 grupos con variantes ortogrÃ¡ficas detectadas |
| `mapeo_colonias_reportes_911.csv` | Mapeo de colonias originales a normalizadas |
| `demografia_limpio.csv` | Datos demogrÃ¡ficos normalizados |
| `colonias_unicas_demografia.csv` | Lista de colonias Ãºnicas de demografÃ­a |

---

## ğŸ› ï¸ EjecuciÃ³n del Dashboard

### ğŸš€ OpciÃ³n 1: Pipeline Completo (Primera vez)

```powershell
# Ejecuta todo el pipeline desde cero (20-30 minutos)
.\run_pipeline.ps1
```

Este script automatiza:
1. Descarga de datos desde Hugging Face
2. Procesamiento y limpieza (feature engineering)
3. GeocodificaciÃ³n de colonias
4. UnificaciÃ³n de datos (spatial join 3 pasos)
5. GeneraciÃ³n de mapa interactivo

### âš¡ OpciÃ³n 2: Regenerar Solo el Mapa (RÃ¡pido)

```powershell
# Si ya tienes datos procesados (2-3 minutos)
.\regenerar_mapa.ps1
```

### ğŸ”§ OpciÃ³n 3: Manual por Pasos

```bash
# 1. Descargar datos raw
python notebooks/download_raw_data.py

# 2. Procesar datos (limpieza + feature engineering)
python notebooks/make_interim_data.py

# 3. Geocodificar reportes 911
python notebooks/geocodificar_colonias_reportes_911.py

# 4. Geocodificar demografÃ­a
python notebooks/geocodificar_colonias_demografia.py

# 5. Unificar datos (CORE)
python notebooks/unificar_datos_poligonos.py

# 6. Generar dashboard
python notebooks/mapa_interactivo_folium_avanzado.py

# 7. Abrir mapa
Invoke-Item mapa_interactivo_hermosillo.html
```

### ğŸ“‹ DocumentaciÃ³n Detallada

Ver [`docs/PIPELINE_DASHBOARD.md`](docs/PIPELINE_DASHBOARD.md) para:
- Pipeline completo paso a paso
- Dependencias entre scripts
- Troubleshooting
- PersonalizaciÃ³n del dashboard

---

## ğŸ—ºï¸ Dashboard Interactivo

El dashboard generado (`mapa_interactivo_hermosillo.html`) incluye:

### 5 Capas de VisualizaciÃ³n
1. ğŸš¨ **Total Incidentes** - Gradiente rojo/amarillo por volumen
2. ğŸ“Š **Tasa per 1k habitantes** - Normalizado por poblaciÃ³n
3. âš ï¸ **Ãndice de Riesgo** (0-100) - Score compuesto de mÃºltiples factores
4. ğŸ”¥ **Score Severidad** (1-3) - PonderaciÃ³n ALTA/MEDIA/BAJA
5. ğŸ‘¥ **PoblaciÃ³n** - DistribuciÃ³n demogrÃ¡fica

### CaracterÃ­sticas
- âœ… 693 polÃ­gonos con mÃ©tricas detalladas
- âœ… Popups con demografÃ­a completa e incidentes
- âœ… Panel de filtros (aÃ±o, trimestre, categorÃ­a, severidad)
- âœ… Herramientas de navegaciÃ³n (zoom, bÃºsqueda, mediciÃ³n)
- âœ… Mini mapa y control de capas
- âœ… Archivo HTML auto-contenido (11.7 MB)

---

## ğŸ› ï¸ Scripts de Procesamiento

### Pipeline de Datos

### Pipeline de Datos

#### 1. Descarga y Procesamiento Base
```bash
# Descarga desde Hugging Face
python notebooks/download_raw_data.py

# Procesamiento con feature engineering
python notebooks/make_interim_data.py
```

#### 2. GeocodificaciÃ³n
```bash
# Geocodificar colonias de reportes 911 (incremental)
python notebooks/geocodificar_colonias_reportes_911.py

# Geocodificar colonias de demografÃ­a
python notebooks/geocodificar_colonias_demografia.py
```

#### 3. UnificaciÃ³n y Dashboard
```bash
# Unificar datos con spatial join (3 pasos)
python notebooks/unificar_datos_poligonos.py

# Generar mapa interactivo
python notebooks/mapa_interactivo_folium_avanzado.py
```

### Scripts de AnÃ¡lisis

```bash
# DiagnÃ³stico de polÃ­gonos sin demografÃ­a
python notebooks/diagnostico_poligonos_sin_demografia.py

# AnÃ¡lisis de calidad de datos demogrÃ¡ficos
python notebooks/analizar_calidad_datos_demografia.py
```

### AnÃ¡lisis

```bash
# Analizar calidad de datos demogrÃ¡ficos
python notebooks/analizar_calidad_datos_demografia.py
```

---

## âš™ï¸ ConfiguraciÃ³n

### Requisitos

```bash
# Python 3.10+
pip install -r requirements.txt
```

**Dependencias principales**:
- `pandas>=2.0.0` - ManipulaciÃ³n de datos
- `googlemaps>=4.10.0` - GeocodificaciÃ³n
- `python-dotenv>=1.0.0` - Variables de entorno

### Google Maps API

Para usar el script de geocodificaciÃ³n:

1. ObtÃ©n una API key de [Google Cloud Console](https://console.cloud.google.com/)
2. Habilita la **Geocoding API**
3. Crea un archivo `.env` en la raÃ­z del proyecto:

```env
GOOGLE_MAPS_API_KEY=tu_api_key_aqui
```

âš ï¸ **IMPORTANTE**: Nunca subas tu API key al repositorio. El archivo `.env` estÃ¡ protegido por `.gitignore`.

Ver [`SECURITY.md`](SECURITY.md) para mÃ¡s detalles de seguridad.

---

## ğŸ“– DocumentaciÃ³n

- **[Proceso de Limpieza de Datos](docs/PROCESO_LIMPIEZA_DATOS.md)**: DocumentaciÃ³n completa del flujo de trabajo
- **[Seguridad](SECURITY.md)**: GuÃ­a de manejo seguro de credenciales

---

## ğŸ“ OrganizaciÃ³n del Proyecto

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Datos originales (sin modificar)
â”‚   â””â”€â”€ processed/              # Datos limpios y procesados
â”‚
â”œâ”€â”€ notebooks/                  # Scripts de anÃ¡lisis y procesamiento
â”‚   â”œâ”€â”€ extraer_colonias_unicas_reportes_911.py
â”‚   â”œâ”€â”€ geocodificar_colonias_reportes_911.py
â”‚   â”œâ”€â”€ normalizar_espacios_demografia.py
â”‚   â””â”€â”€ analizar_calidad_datos_demografia.py
â”‚
â”œâ”€â”€ docs/                       # DocumentaciÃ³n del proyecto
â”‚   â””â”€â”€ PROCESO_LIMPIEZA_DATOS.md
â”‚
â”œâ”€â”€ .env                        # Variables de entorno (NO SUBIR)
â”œâ”€â”€ .gitignore                  # Archivos ignorados por Git
â”œâ”€â”€ SECURITY.md                 # GuÃ­a de seguridad
â””â”€â”€ README.md                   # Este archivo
```

---

## ğŸ”¬ MetodologÃ­a de Limpieza

### Pipeline de Datos

**Flujo**: Hugging Face â†’ Raw â†’ Interim â†’ Processed

1. **Descarga** (`download_raw_data.py`):
   - Fuente: Hugging Face dataset `Marcelinux/llamadas911_colonias_hermosillo_2018_2025`
   - Formato: Excel multi-hoja (8 hojas: 2018-2025)
   - Output: `data/raw/reportes_de_incidentes_2018_2025.csv`

2. **Procesamiento Interim** (`make_interim_data.py`):
   - **EstandarizaciÃ³n**: 475 tipos de incidentes â†’ 198 Ãºnicos (mapa de normalizaciÃ³n)
   - **CategorizaciÃ³n**: 12 categorÃ­as principales de incidentes
   - **Niveles de severidad**: BAJA, MEDIA, ALTA (200 reglas)
   - **Feature Engineering**:
     * `ParteDelDia`: Madrugada/MaÃ±ana/Tarde/Noche
     * `DiaDeLaSemana`: Lunes-Domingo
     * `EsFinDeSemana`: Boolean
     * `Mes`: 1-12
     * `EsQuincena`: Boolean (dÃ­as 1, 14-16, 28-31)
   - **OptimizaciÃ³n**: Columnas temporales redundantes eliminadas (FECHA, HORA, AÃ±o_Reporte)
   - Output: `data/interim/reportes_de_incidentes_procesados_2018_2025.csv` (~310MB)

### NormalizaciÃ³n de Colonias

**Problema**: 2,296 nombres de colonias con mÃºltiples errores ortogrÃ¡ficos

**SoluciÃ³n**: Algoritmo de fuzzy matching que:
1. Normaliza texto (acentos, mayÃºsculas, espacios)
2. Calcula similitud entre nombres (90% umbral)
3. Valida que sean variantes reales (no colonias diferentes)
4. Selecciona el nombre mÃ¡s frecuente como representativo

**Resultado**: 2,047 colonias Ãºnicas consolidadas (220 grupos con variantes)

### GeocodificaciÃ³n Incremental

**Proceso**: Google Maps Geocoding API con sistema anti-duplicados
- DetecciÃ³n automÃ¡tica de colonias ya geocodificadas
- Solo procesa colonias nuevas (ahorro de costos)
- Formato: `"{colonia}, Hermosillo, Sonora, MÃ©xico"`
- Delay: 0.2s entre peticiones
- Tasa de Ã©xito: ~100%

---

## ğŸ“ˆ MÃ©tricas de Calidad

| Dataset | Registros | Colonias Ãšnicas | Variantes Detectadas | Calidad |
|---------|-----------|-----------------|----------------------|---------|
| Datos Policiales (2018-2025) | 2,297,081 | 2,047 | 220 grupos (-9.8%) | â­â­â­â­ |
| Datos DemogrÃ¡ficos | 660 | 659 | 1 (-0.15%) | â­â­â­â­â­ |

### EstandarizaciÃ³n de Incidentes

| MÃ©trica | Valor |
|---------|-------|
| Tipos originales | 475 |
| Tipos estandarizados | 198 |
| CategorÃ­as principales | 12 |
| Niveles de severidad | 3 (BAJA, MEDIA, ALTA) |
| Periodo de datos | 2018-01-01 a 2025-09-30 |

---

## ğŸ‘¥ Equipo

**OrganizaciÃ³n**: Equipo-seguridad-y-desarrollo  
**Rama actual**: `colonias_geolocalizadas_unificadas`

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo licencia [LICENSE](LICENSE).

---

## ğŸ¤ Contribuciones

Para contribuir al proyecto:
1. Revisa la documentaciÃ³n en [`docs/`](docs/)
2. Sigue las convenciones de nomenclatura establecidas
3. Documenta todos los cambios importantes
4. Nunca subas credenciales o API keys

---

*Ãšltima actualizaciÃ³n: 6 de noviembre de 2025*

## Project Organization

```
â”œâ”€â”€ LICENSE            <- Open-source license if one is chosen
â”œâ”€â”€ Makefile           <- Makefile with convenience commands like `make data` or `make train`
â”œâ”€â”€ README.md          <- The top-level README for developers using this project.
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ external       <- Data from third party sources.
â”‚   â”œâ”€â”€ interim        <- Intermediate data that has been transformed.
â”‚   â”œâ”€â”€ processed      <- The final, canonical data sets for modeling.
â”‚   â””â”€â”€ raw            <- The original, immutable data dump.
â”‚
â”œâ”€â”€ docs               <- A default mkdocs project; see www.mkdocs.org for details
â”‚
â”œâ”€â”€ models             <- Trained and serialized models, model predictions, or model summaries
â”‚
â”œâ”€â”€ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
â”‚                         the creator's initials, and a short `-` delimited description, e.g.
â”‚                         `1.0-jqp-initial-data-exploration`.
â”‚
â”œâ”€â”€ pyproject.toml     <- Project configuration file with package metadata for 
â”‚                         indice-delictivo-hermosillo and configuration for tools like black
â”‚
â”œâ”€â”€ references         <- Data dictionaries, manuals, and all other explanatory materials.
â”‚
â”œâ”€â”€ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
â”‚   â””â”€â”€ figures        <- Generated graphics and figures to be used in reporting
â”‚
â”œâ”€â”€ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
â”‚                         generated with `pip freeze > requirements.txt`
â”‚
â”œâ”€â”€ setup.cfg          <- Configuration file for flake8
â”‚
â””â”€â”€ indice-delictivo-hermosillo   <- Source code for use in this project.
    â”‚
    â”œâ”€â”€ __init__.py             <- Makes indice-delictivo-hermosillo a Python module
    â”‚
    â”œâ”€â”€ config.py               <- Store useful variables and configuration
    â”‚
    â”œâ”€â”€ dataset.py              <- Scripts to download or generate data
    â”‚
    â”œâ”€â”€ features.py             <- Code to create features for modeling
    â”‚
    â”œâ”€â”€ modeling                
    â”‚   â”œâ”€â”€ __init__.py 
    â”‚   â”œâ”€â”€ predict.py          <- Code to run model inference with trained models          
    â”‚   â””â”€â”€ train.py            <- Code to train models
    â”‚
    â””â”€â”€ plots.py                <- Code to create visualizations
```

--------

