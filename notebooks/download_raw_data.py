# -*- coding: utf-8 -*-
"""download_raw_data

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17zqkToqR5d94zIBAAPgeu5UQ9KgF5N27
"""

# src/data/get_raw_data.py

import requests
import pandas as pd
from pathlib import Path
import sys
import io

# URL por defecto (archivo en Hugging Face). Puedes cambiarla si es necesario.
DEFAULT_URL = (
    "https://huggingface.co/datasets/Marcelinux/llamadas911_colonias_hermosillo_2018_2025/resolve/main/213.xlsx"
)

# Nombre del archivo CSV de salida para que el resto del flujo sea compatible
OUTPUT_FILE = "reportes_de_incidentes_2018_2025.csv"


def fetch_and_consolidate_raw_data(output_dir: Path, url: str = DEFAULT_URL):
    """
    Descarga un archivo desde `url` (Hugging Face) y lo convierte a CSV
    guardándolo como `reportes_de_incidentes_2018_2025.csv` dentro de `output_dir`.

    El comportamiento está intencionalmente simple: descarga un único fichero
    (puede ser .xlsx o .csv). Si es Excel lo convierte a CSV para mantener la
    compatibilidad con el resto del pipeline.
    """
    try:
        print("Iniciando descarga desde:", url)

        # Petición HTTP
        resp = requests.get(url, stream=True, timeout=120)
        resp.raise_for_status()

        # Leer contenido en memoria
        content = resp.content
        buf = io.BytesIO(content)

        # Intentar leer como CSV primero, si falla probar Excel
        try:
            df = pd.read_csv(io.StringIO(content.decode('utf-8')))
            print("Archivo leído como CSV directamente.")
        except Exception:
            try:
                buf.seek(0)
                # Leer todas las hojas si el Excel tiene varias
                xls = pd.read_excel(buf, sheet_name=None)
                if isinstance(xls, dict):
                    dfs = []
                    for sheet_name, df_sheet in xls.items():
                        # Mantener una copia e intentar extraer el año del nombre de la hoja
                        tmp = df_sheet.copy()
                        # Intenta convertir el nombre de la hoja a año (ej: "2018" -> 2018)
                        try:
                            year = int(sheet_name)
                        except ValueError:
                            # Si no es un número, intenta extraer el año del nombre o usa None
                            year = None
                        tmp['Año_Reporte'] = year
                        dfs.append(tmp)
                    df = pd.concat(dfs, ignore_index=True)
                    print(f"Archivo Excel con {len(dfs)} hojas leídas y concatenadas con Año_Reporte.")
                else:
                    # Si por alguna razón pd.read_excel devuelve un DataFrame
                    df = xls
                    # Intenta extraer año o asigna None
                    df['Año_Reporte'] = None
                    print("Archivo leído como Excel (una sola hoja).")
            except Exception as e:
                print(f"No fue posible parsear el archivo descargado: {e}", file=sys.stderr)
                return None

        # Guardar como CSV en el directorio de salida
        output_dir.mkdir(parents=True, exist_ok=True)
        output_path = output_dir / OUTPUT_FILE
        df.to_csv(output_path, index=False, encoding='utf-8-sig')

        print(f"✅ Éxito: archivo guardado en {output_path}")
        return output_path

    except requests.HTTPError as e:
        print(f"HTTP error al descargar: {e}", file=sys.stderr)
        return None
    except requests.RequestException as e:
        print(f"Error de conexión al descargar: {e}", file=sys.stderr)
        return None
    except Exception as e:
        print(f"Error inesperado: {e}", file=sys.stderr)
        return None

# --- Bloque de ejecución para pruebas ---
if __name__ == "__main__":
    """
    Este bloque solo se ejecuta cuando corres este archivo directamente
    """
    test_output_dir = Path.cwd() / "data" / "raw"
    fetch_and_consolidate_raw_data(output_dir=test_output_dir)