{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c51bf321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joel_\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codificación detectada para ..\\data\\raw\\213.csv: utf-8\n",
      "Archivo '..\\data\\raw\\213.csv' cargado exitosamente.\n",
      "Se encontraron 1338 variaciones de colonias (limpias).\n",
      "Iniciando proceso de estandarización (umbral=96%)...\n",
      "Proceso completado. Se agruparon en 1280 colonias canónicas.\n",
      "\n",
      "Diccionario de mapeo guardado en: ..\\data\\raw\\diccionario_colonias.csv\n",
      "Archivo con correcciones guardado en: ..\\data\\raw\\delitos.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process, fuzz\n",
    "import chardet\n",
    "import re\n",
    "import unicodedata \n",
    "\n",
    "# --- 1. limpieza y encoding ---\n",
    "\n",
    "def get_encoding(file_path):\n",
    "    \"\"\"Detecta la codificación de un archivo.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            result = chardet.detect(f.read(100000))\n",
    "        encoding = result['encoding']\n",
    "        print(f\"Codificación detectada para {file_path}: {encoding}\")\n",
    "        return encoding\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: No se encontró el archivo {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error detectando encoding: {e}\")\n",
    "        return 'utf-8'\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    \"\"\"Limpia y estandariza un string para una mejor comparación.\"\"\"\n",
    "    if not isinstance(texto, str):\n",
    "        return \"\"\n",
    "    \n",
    "    texto = unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('utf-8')\n",
    "    texto = texto.upper().strip()\n",
    "    texto = re.sub(r'^(COLONIA|COL|FRACCIONAMIENTO|FRACC|RESIDENCIAL|RES|PRIVADA|PRIV)\\s+', '', texto)\n",
    "    texto = re.sub(r'[^A-Z0-9\\s]', '', texto)\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "    \n",
    "    return texto\n",
    "\n",
    "# --- 2. Carga y Preparación de Datos ---\n",
    "\n",
    "# Asumiendo que tus archivos de salida van al mismo directorio que el de entrada\n",
    "data_path = r\"..\\data\\raw\"\n",
    "file_path = fr\"{data_path}\\213.csv\" \n",
    "encoding = get_encoding(file_path)\n",
    "\n",
    "if encoding is None:\n",
    "    exit() \n",
    "\n",
    "try:\n",
    "    df_delitos = pd.read_csv(file_path, encoding=encoding, low_memory=False)\n",
    "    print(f\"Archivo '{file_path}' cargado exitosamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al leer el archivo CSV: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Guardamos la columna original antes de limpiarla\n",
    "df_delitos['Colonia_Original'] = df_delitos['COLONIA'].fillna('SIN INFORMACION')\n",
    "\n",
    "df_delitos['Colonia_Limpia'] = df_delitos['Colonia_Original'].apply(limpiar_texto)\n",
    "target_colonias = df_delitos['Colonia_Limpia'].dropna().unique()\n",
    "target_colonias.sort() \n",
    "\n",
    "print(f\"Se encontraron {len(target_colonias)} variaciones de colonias (limpias).\")\n",
    "\n",
    "# --- 3. Lógica de Agrupación (Fuzzy Matching contra el mismo archivo) ---\n",
    "\n",
    "mapping_limpio_a_canonico = {}\n",
    "lista_canonica = [] \n",
    "\n",
    "# --- CAMBIO 1: Umbral subido a 96 para diferenciar '4 DE MARZO' de '14 DE MARZO' \n",
    "threshold = 96 \n",
    "\n",
    "print(f\"Iniciando proceso de estandarización (umbral={threshold}%)...\")\n",
    "\n",
    "for colonia in target_colonias:\n",
    "    if not colonia or colonia == \"SIN INFORMACION\": \n",
    "        mapping_limpio_a_canonico[colonia] = \"SIN INFORMACION\"\n",
    "        continue\n",
    "\n",
    "    if not lista_canonica:\n",
    "        lista_canonica.append(colonia)\n",
    "        mapping_limpio_a_canonico[colonia] = colonia\n",
    "        continue\n",
    "\n",
    "    best_match, score = process.extractOne(colonia, lista_canonica, scorer=fuzz.token_sort_ratio)\n",
    "\n",
    "    if score >= threshold:\n",
    "        mapping_limpio_a_canonico[colonia] = best_match\n",
    "    else:\n",
    "        mapping_limpio_a_canonico[colonia] = colonia\n",
    "        lista_canonica.append(colonia) \n",
    "\n",
    "print(f\"Proceso completado. Se agruparon en {len(lista_canonica)} colonias canónicas.\")\n",
    "\n",
    "# --- 4. Crear y Guardar el Diccionario de Mapeo ---\n",
    "\n",
    "df_delitos['Colonia_Corregida'] = df_delitos['Colonia_Limpia'].map(mapping_limpio_a_canonico)\n",
    "\n",
    "diccionario_final = df_delitos[['Colonia_Original', 'Colonia_Corregida']].drop_duplicates()\n",
    "diccionario_final = diccionario_final.rename(columns={\n",
    "    'Colonia_Original': 'Original', \n",
    "    'Colonia_Corregida': 'Corregida'\n",
    "})\n",
    "diccionario_final = diccionario_final.sort_values(by=['Corregida', 'Original'])\n",
    "\n",
    "# --- CAMBIO 2: Guardar el diccionario en la misma carpeta 'data\\raw'\n",
    "output_dict_path = fr'{data_path}\\diccionario_colonias.csv'\n",
    "try:\n",
    "    diccionario_final.to_csv(output_dict_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nDiccionario de mapeo guardado en: {output_dict_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al guardar el diccionario: {e}\")\n",
    "\n",
    "# --- 5. Guardar el archivo corregido como 'delitos.csv' ---\n",
    "\n",
    "output_corrected_path = fr'{data_path}\\delitos.csv' \n",
    "\n",
    "try:\n",
    "    # 1. Sobrescribe la columna original 'COLONIA' con los valores corregidos\n",
    "    df_delitos['COLONIA'] = df_delitos['Colonia_Corregida']\n",
    "    \n",
    "    # 2. Crea un nuevo DataFrame final eliminando las columnas de ayuda\n",
    "    df_final = df_delitos.drop(columns=['Colonia_Original', 'Colonia_Limpia', 'Colonia_Corregida'])\n",
    "    \n",
    "    # 3. Guarda el DataFrame limpio\n",
    "    df_final.to_csv(output_corrected_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"Archivo con correcciones guardado en: {output_corrected_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al guardar el archivo corregido: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b996fadf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
