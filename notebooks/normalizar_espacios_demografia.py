"""
Script para limpiar nombres de colonias en demografia_hermosillo.csv

Objetivo:
- SOLO corregir errores ortogr√°ficos obvios (espacios extra, espacios no separables,
    comillas/l√≠mites basura, caracteres invisibles)
- Mantener colonias diferentes como entidades separadas (NO fuzzy matching, NO
    eliminaci√≥n de palabras como 'EL', 'LA', ni sufijos como 'INDECO')
- Deduplicar solo por coincidencia EXACTA tras la limpieza (e.g., "Col  X" == "Col X")

Ejemplos que deben permanecer distintos:
- "EL SAHUARO" ‚â† "SAHUARO" ‚â† "SAHUARO INDECO"
"""

import pandas as pd
import unicodedata
import re
from typing import Dict


def reparar_mojibake(s: str) -> str:
    """Intenta reparar texto con mojibake t√≠pico (UTF-8 le√≠do como Latin-1).

    Si el round-trip latin1->utf-8 falla, retorna el original.
    """
    if not s:
        return s
    try:
        return s.encode('latin1').decode('utf-8')
    except Exception:
        return s


def limpiar_colonia(texto: str, alias_map: Dict[str, str]) -> str:
    """Limpia etiqueta de colonia y aplica alias controlados para homogeneizar joins.

    Pasos:
    1. Normalizaci√≥n unicode NFC.
    2. Reparar mojibake simple.
    3. Espacios (NBSP -> espacio, colapso, trim, retirar puntuaci√≥n perif√©rica).
    4. Aplicar alias EXACTOS (en may√∫sculas) definidos en alias_map.
    5. NO eliminar stopwords (EL, LA, DE, etc.).
    """
    if pd.isna(texto):
        return ""
    s = str(texto)
    s = unicodedata.normalize("NFC", s)
    s = reparar_mojibake(s)
    s = s.replace("\u00A0", " ")
    s = s.strip()
    s = re.sub(r"\s+", " ", s)
    s = s.strip("'\"‚Äú‚Äù‚Äò‚Äô.;,|/\\- ")
    s = re.sub(r"\s+", " ", s)
    # Alias: trabajamos en may√∫sculas para la clave, pero retornamos en la forma destino del alias
    upper = s.upper()
    if upper in alias_map:
        return alias_map[upper]
    return s


def main():
    print("="*70)
    print("LIMPIEZA DE COLONIAS - DEMOGRAF√çA HERMOSILLO")
    print("="*70)
    
    # Leer datos (usar pathlib para rutas relativas correctas)
    from pathlib import Path
    project_root = Path(__file__).parent.parent
    archivo = project_root / 'data' / 'raw' / 'demografia_hermosillo.csv'
    print(f"\nüìÇ Leyendo datos desde: {archivo}")
    df = pd.read_csv(archivo)
    
    print(f"‚úì Total de registros: {len(df):,}")
    
    # Contar colonias √∫nicas antes
    colonias_antes = df['nom_col'].nunique()
    print(f"\nüìä Colonias √∫nicas (antes de limpiar): {colonias_antes:,}")
    
    # Aplicar limpieza ortogr√°fica m√≠nima (sin agrupar nombres distintos)
    print("\nüîß Limpiando etiquetas (espacios, NBSP, bordes/puntuaci√≥n)...")
    # Construir alias controlados √∫nicamente para casos detectados que impiden join.
    # Mantenerlos m√≠nimos y documentados.
    alias_map = {
        # Correcciones de truncaci√≥n / falta de tilde / letras perdidas
        'AMPLIACIN 4 DE MARZO': 'AMPLIACION 4 DE MARZO',
        'ARGANGEL RESIDENCIAL': 'ARCANGEL RESIDENCIAL',
        'BUROCRATA MUNICIPAL': 'BUR√ìCRATA MUNICIPAL',  # si en pol√≠gono aparece con acento
        'CASA ALTA RDCIAL': 'CASA ALTA RESIDENCIAL',
        'CARDENO RESIDENCIAL': 'CARDENO RESIDENCIAL',  # placeholder (permite consistencia si ya existe as√≠ en pol√≠gonos)
        'CARDENO ENTORNO': 'CARDENO ENTORNO',  # sin cambio a√∫n; revisar si existe hom√≥nimo
        'CA√ëA√ëA DE LOS NEGROS': 'CA√ëADA DE LOS NEGROS',  # mojibake doble
        'LA CORU√ëA SECCION PRIVADA ORZAN': 'LA CORU√ëA SECCION PRIVADA ORZAN',
        'LA CORU√ëA SECCION  PRIVADA ALMAR': 'LA CORU√ëA SECCION PRIVADA ALMAR',
        'LAS LOMAS SECC CASTA√ëOS': 'LAS LOMAS SECCION CASTA√ëOS',
        'LAS PLASITAS PRIMERAS': 'LAS PLAZITAS PRIMERAS',
        'NUEVA ESPA√ëA': 'NUEVA ESPA√ëA',  # identidad
        'PARAISO PITIC': 'PARAISO PITIC',
        # Casos de mojibake comunes sin alias espec√≠fico se corrigen en reparar_mojibake
    }

    df['nom_col_norm'] = df['nom_col'].apply(lambda x: limpiar_colonia(x, alias_map))
    
    # Contar cambios
    cambios = (df['nom_col'] != df['nom_col_norm']).sum()
    print(f"‚úì Registros con correcci√≥n aplicada: {cambios}")
    
    # Mostrar ejemplos de cambios
    if cambios > 0:
        print("\nüìù Ejemplos de correcciones:")
        ejemplos = df[df['nom_col'] != df['nom_col_norm']][['nom_col', 'nom_col_norm']].drop_duplicates()
        for _, row in ejemplos.head(10).iterrows():
            print(f"  '{row['nom_col']}' ‚Üí '{row['nom_col_norm']}'")
    
    # Mantener ambas columnas: nom_col (original) y nom_col_norm (normalizada)
    # Esto evita romper joins existentes basados en el nombre original y permite usar la normalizada como fallback.
    
    # Contar colonias √∫nicas despu√©s
    colonias_despues = df['nom_col_norm'].nunique()
    print(f"\nüìä Colonias √∫nicas (despu√©s de limpiar): {colonias_despues:,}")
    print(f"‚úì Colonias consolidadas: {colonias_antes - colonias_despues}")
    
    # Guardar archivo limpio
    archivo_salida = project_root / 'data' / 'processed' / 'demografia_limpio.csv'
    df.to_csv(archivo_salida, index=False, encoding='utf-8-sig')
    print(f"\nüíæ Guardado: {archivo_salida}")
    
    # Guardar lista de colonias √∫nicas
    colonias_unicas = sorted(df['nom_col_norm'].unique())
    df_colonias = pd.DataFrame({'nom_col_norm': colonias_unicas})
    archivo_colonias = project_root / 'data' / 'processed' / 'colonias_unicas_demografia.csv'
    df_colonias.to_csv(archivo_colonias, index=False, encoding='utf-8-sig')
    print(f"üíæ Guardado: {archivo_colonias}")
    
    print("\n" + "="*70)
    print("RESUMEN:")
    print("="*70)
    print(f"Total de registros: {len(df):,}")
    print(f"Colonias √∫nicas: {colonias_despues:,}")
    print(f"Correcciones aplicadas: Espacios/NBSP, recortes de borde y puntuaci√≥n")
    print("="*70)


if __name__ == "__main__":
    main()
